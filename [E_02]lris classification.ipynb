{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba81451",
   "metadata": {},
   "source": [
    "# [E_02]lris classification\n",
    "\n",
    "## 목차\n",
    "**1. [라이브러리 import](#1.-라이브러리-import)**  \n",
    "**2. [손글씨 분류하기](#2.-손글씨-분류하기)**  \n",
    "**&#160;&#160; 2-1. [데이터 살펴보기](#2-1.-데이터-살펴보기)**  \n",
    "**&#160;&#160; 2-2. [데이터 전처리](#2-2.-데이터-전처리)**  \n",
    "**&#160;&#160; 2-3. [학습하기 & 테스트하기](#2-3.-학습하기-&-테스트하기)**  \n",
    "**3. [와인 분류하기](#3.-와인-분류하기)**  \n",
    "**&#160;&#160; 3-1. [데이터 살펴보기](#3-1.-데이터-살펴보기)**  \n",
    "**&#160;&#160; 3-2. [데이터 전처리](#3-2.-데이터-전처리)**  \n",
    "**&#160;&#160; 3-3. [학습하기 & 테스트하기](#3-3.-학습하기-&-테스트하기)**  \n",
    "**4. [유방암 데이터 분류하기](#4.-유방암-데이터-분류하기)**  \n",
    "**&#160;&#160; 4-1. [데이터 살펴보기](#4-1.-데이터-살펴보기)**  \n",
    "**&#160;&#160; 4-2. [데이터 전처리](#4-2.-데이터-전처리)**  \n",
    "**&#160;&#160; 4-3. [학습하기 & 테스트하기](#4-3.-학습하기-&-테스트하기)**  \n",
    "\n",
    "\n",
    "---\n",
    "### 루브릭 평가기준\n",
    "|**평가문항**|**상세기준**|\n",
    "|:---|:---|\n",
    "|1. 3가지 데이터셋의 구성이 합리적으로 진행되었는가?|feature와 label 선정을 위한 데이터 분석과정이 체계적으로 전개됨|\n",
    "|2. 3가지 데이터셋에 대해 각각 5가지 모델을 성공적으로 적용하였는가?|모델학습 및 테스트가 정상적으로 수행되었음|\n",
    "|3. 3가지 데이터셋에 대해 모델의 평가지표가 적절히 선택되었는가?|평가지표 선택 및 이유 설명이 타당함|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30befb1",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1b440f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339f3dc",
   "metadata": {},
   "source": [
    "## 2. 손글씨 분류하기\n",
    "### 2-1. 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861639c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits객체의 변수와 메서드: ['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n",
      "digits객체의 키: dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
      "\n",
      "분류시 학습하는 특징: ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
      "분류시 학습하는 특징의 개수: 64\n",
      "digits_data의 shape: (1797, 64)\n",
      "digits_data의 0번째 데이터 ((64,) -> (8,8)로 reshape): \n",
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "\n",
      "분류할 정답(target): [0 1 2 3 4 5 6 7 8 9]\n",
      "digits_label의 shape: (1797,)\n",
      "digits_label의 0번째 데이터: [0]\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "print(f'digits객체의 변수와 메서드: {dir(digits)}')\n",
    "print(f'digits객체의 키: {digits.keys()}\\n')\n",
    "\n",
    "digits_data = digits.data\n",
    "print(f'분류시 학습하는 특징: {digits.feature_names}')\n",
    "print(f'분류시 학습하는 특징의 개수: {len(digits.feature_names)}')\n",
    "print(f'digits_data의 shape: {digits_data.shape}')\n",
    "print(f'digits_data의 0번째 데이터 ((64,) -> (8,8)로 reshape): \\n{digits_data[0].reshape((8,8))}\\n')\n",
    "\n",
    "digits_label = digits.target\n",
    "print(f'분류할 정답(target): {digits.target_names}')\n",
    "print(f'digits_label의 shape: {digits_label.shape}')\n",
    "print(f'digits_label의 0번째 데이터: {digits_label[0:1]}\\n')\n",
    "print('\\n**************************************************\\n')\n",
    "\n",
    "# digits에 대한 설명\n",
    "# print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f8c5ba",
   "metadata": {},
   "source": [
    "### 2-2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f74eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수: 1437, X_test 개수: 360\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "print(f'X_train 개수: {len(X_train)}, X_test 개수: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b20d6",
   "metadata": {},
   "source": [
    "### 2-3. 학습하기 & 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb90ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터셋 - X_train의 모양: (1437, 64), y_train의 모양: (1437,)\n",
      "테스트 데이터셋 - X_test의 모양: (360, 64), y_test의 모양: (360,)\n"
     ]
    }
   ],
   "source": [
    "print(f'학습 데이터셋 - X_train의 모양: {X_train.shape}, y_train의 모양: {y_train.shape}')\n",
    "print(f'테스트 데이터셋 - X_test의 모양: {X_test.shape}, y_test의 모양: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407cefa",
   "metadata": {},
   "source": [
    "### 의사결정나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b896165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n",
      "모델 정확도: 85.55555555555556%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c35991",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5609a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n",
      "모델 정확도: 96.38888888888889%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacba6a1",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba52504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "모델 정확도: 98.88888888888889%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ed6e3",
   "metadata": {},
   "source": [
    "### SGD (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abe45e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.97      0.81      0.88        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.97      0.88      0.92        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       0.68      1.00      0.81        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.90      0.88      0.89        43\n",
      "           9       0.90      0.88      0.89        32\n",
      "\n",
      "    accuracy                           0.93       360\n",
      "   macro avg       0.93      0.93      0.93       360\n",
      "weighted avg       0.94      0.93      0.93       360\n",
      "\n",
      "모델 정확도: 93.05555555555556%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b110d1d1",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f13dff24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       0.97      1.00      0.99        37\n",
      "           5       0.82      0.96      0.89        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.91      0.94        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "모델 정확도: 95.27777777777777%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f59d8d2",
   "metadata": {},
   "source": [
    "### 종합 평가\n",
    "Accuracy: 종합적인 정확도 평가  \n",
    "Precision: 양성예측 클래스(TP, FP)중 실제 양성클래스의 비율(정밀도)\n",
    "Recall: 실제양성 클래스(TP, FN)중 양성클래스라고 예측한것의 비율(재현율)  \n",
    "\n",
    "### <center>digits 모델에 따른 평가점수</center>\n",
    "\n",
    "||**Accuracy**|**Precision**|**Recall**|\n",
    "|:---|:---|:---|:---|\n",
    "|**decision_tree(의사결정나무)**|86|86|86\n",
    "|**랜덤 포레스트(Random Forest)**|96|96|96|\n",
    "|**Support Vector Machine (SVM)**|99|99|99|\n",
    "|**SGD (Stochastic Gradient Descent)**|94|94|94\n",
    "|**Logistic Regression**|95|95|95|\n",
    "\n",
    "<br>\n",
    "\n",
    "80점 미만으로 나온 의사결정 나무를 제외하면 모두 적합해보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5159e4",
   "metadata": {},
   "source": [
    "## 3. 와인 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e926608c",
   "metadata": {},
   "source": [
    "### 3-1. 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61e0f6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine객체의 변수와 메서드: ['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']\n",
      "wine객체의 키: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n",
      "\n",
      "분류시 학습하는 특징: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "분류시 학습하는 특징의 개수: 13\n",
      "wine_data의 shape: (178, 13)\n",
      "wine_data의 0번째 데이터: \n",
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      "\n",
      "분류할 정답(target): ['class_0' 'class_1' 'class_2']\n",
      "digits_label의 shape: (178,)\n",
      "digits_label의 0~10번째 데이터: [0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "\n",
    "print(f'wine객체의 변수와 메서드: {dir(wine)}')\n",
    "print(f'wine객체의 키: {wine.keys()}\\n')\n",
    "\n",
    "wine_data = wine.data\n",
    "print(f'분류시 학습하는 특징: {wine.feature_names}')\n",
    "print(f'분류시 학습하는 특징의 개수: {len(wine.feature_names)}')\n",
    "print(f'wine_data의 shape: {wine_data.shape}')\n",
    "print(f'wine_data의 0번째 데이터: \\n{wine_data[0]}\\n')\n",
    "\n",
    "wine_label = wine.target\n",
    "print(f'분류할 정답(target): {wine.target_names}')\n",
    "print(f'digits_label의 shape: {wine_label.shape}')\n",
    "print(f'digits_label의 0~10번째 데이터: {wine_label[0:10]}\\n')\n",
    "print('\\n**************************************************\\n')\n",
    "\n",
    "# wine에 대한 설명\n",
    "# print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca21793",
   "metadata": {},
   "source": [
    " ### 3-2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6190bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수: 142, X_test 개수: 36\n",
      "학습 데이터셋 - X_train의 모양: (142, 13), y_train의 모양: (142,)\n",
      "테스트 데이터셋 - X_test의 모양: (36, 13), y_test의 모양: (36,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "print(f'X_train 개수: {len(X_train)}, X_test 개수: {len(X_test)}')\n",
    "print(f'학습 데이터셋 - X_train의 모양: {X_train.shape}, y_train의 모양: {y_train.shape}')\n",
    "print(f'테스트 데이터셋 - X_test의 모양: {X_test.shape}, y_test의 모양: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934355b",
   "metadata": {},
   "source": [
    "### 3-3. 학습하기 & 테스트하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4ea60d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "모델 정확도: 94.44444444444444%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "모델 정확도: 100.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n",
      "모델 정확도: 61.111111111111114%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         7\n",
      "           1       0.91      0.59      0.71        17\n",
      "           2       0.55      0.50      0.52        12\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.65      0.70      0.63        36\n",
      "weighted avg       0.71      0.64      0.64        36\n",
      "\n",
      "모델 정확도: 63.888888888888886%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.95      0.96        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "모델 정확도: 97.22222222222221%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# decision_tree(의사결정나무)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')\n",
    "\n",
    "\n",
    "# 랜덤 포레스트(Random Forest)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')\n",
    "\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')\n",
    "\n",
    "\n",
    "# SGD (Stochastic Gradient Descent)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d01c36f",
   "metadata": {},
   "source": [
    "### <center>wine 모델에 따른 평가점수</center>\n",
    "\n",
    "||**Accuracy**|**Precision**|**Recall**|\n",
    "|:---|:---|:---|:---|\n",
    "|**decision_tree(의사결정나무)**|94|96|94|\n",
    "|**랜덤 포레스트(Random Forest)**|100|100||100\n",
    "|**Support Vector Machine (SVM)**|61|59|61|\n",
    "|**SGD (Stochastic Gradient Descent)**|61|52|57|\n",
    "|**Logistic Regression**|97|98|95|\n",
    "\n",
    "<br>\n",
    "\n",
    "점수가 50~60사이인 SVM, SGD를 제외하면 나머지 세 개 모델은 적합해보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e583db28",
   "metadata": {},
   "source": [
    "## 4. 유방암 데이터 분류하기\n",
    "### 4-1. 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6778c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine객체의 변수와 메서드: ['DESCR', 'data', 'data_module', 'feature_names', 'filename', 'frame', 'target', 'target_names']\n",
      "wine객체의 키: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "\n",
      "분류시 학습하는 특징: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "분류시 학습하는 특징의 개수: 30\n",
      "wine_data의 shape: (569, 30)\n",
      "wine_data의 0번째 데이터: \n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n",
      "\n",
      "분류할 정답(target): ['malignant' 'benign']\n",
      "digits_label의 shape: (569,)\n",
      "digits_label의 0~10번째 데이터: [0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "print(f'wine객체의 변수와 메서드: {dir(breast_cancer)}')\n",
    "print(f'wine객체의 키: {breast_cancer.keys()}\\n')\n",
    "\n",
    "breast_cancer_data = breast_cancer.data\n",
    "print(f'분류시 학습하는 특징: {breast_cancer.feature_names}')\n",
    "print(f'분류시 학습하는 특징의 개수: {len(breast_cancer.feature_names)}')\n",
    "print(f'wine_data의 shape: {breast_cancer_data.shape}')\n",
    "print(f'wine_data의 0번째 데이터: \\n{breast_cancer_data[0]}\\n')\n",
    "\n",
    "breast_cancer_label = breast_cancer.target\n",
    "print(f'분류할 정답(target): {breast_cancer.target_names}')\n",
    "print(f'digits_label의 shape: {breast_cancer_label.shape}')\n",
    "print(f'digits_label의 0~10번째 데이터: {breast_cancer_label[0:10]}\\n')\n",
    "print('\\n**************************************************\\n')\n",
    "\n",
    "# breast_cancer에 대한 설명\n",
    "# print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7337f137",
   "metadata": {},
   "source": [
    "### 4-2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbad1655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수: 455, X_test 개수: 114\n",
      "학습 데이터셋 - X_train의 모양: (455, 30), y_train의 모양: (455,)\n",
      "테스트 데이터셋 - X_test의 모양: (114, 30), y_test의 모양: (114,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data, \n",
    "                                                    breast_cancer_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "print(f'X_train 개수: {len(X_train)}, X_test 개수: {len(X_test)}')\n",
    "print(f'학습 데이터셋 - X_train의 모양: {X_train.shape}, y_train의 모양: {y_train.shape}')\n",
    "print(f'테스트 데이터셋 - X_test의 모양: {X_test.shape}, y_test의 모양: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169006fc",
   "metadata": {},
   "source": [
    "### 4-3. 학습하기 & 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2586db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "모델 정확도: 91.22807017543859%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n",
      "모델 정확도: 100.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        40\n",
      "           1       0.87      1.00      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n",
      "모델 정확도: 90.35087719298247%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82        40\n",
      "           1       0.86      1.00      0.92        74\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.93      0.85      0.87       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "모델 정확도: 89.47368421052632%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        40\n",
      "           1       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "모델 정확도: 94.73684210526315%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# decision_tree(의사결정나무)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')\n",
    "\n",
    "\n",
    "# 랜덤 포레스트(Random Forest)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')\n",
    "\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')\n",
    "\n",
    "\n",
    "# SGD (Stochastic Gradient Descent)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'모델 정확도: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187984c8",
   "metadata": {},
   "source": [
    "### <center>breast_cancer 모델에 따른 평가점수</center>\n",
    "\n",
    "||**Accuracy**|**Precision**|**Recall**|\n",
    "|:---|:---|:---|:---|\n",
    "|**decision_tree(의사결정나무)**|91|91|98|\n",
    "|**랜덤 포레스트(Random Forest)**|100|100|100|\n",
    "|**Support Vector Machine (SVM)**|90|94|86|\n",
    "|**SGD (Stochastic Gradient Descent)**|90|91|88|\n",
    "|**Logistic Regression**|95|96|93|\n",
    "\n",
    "<br>\n",
    "\n",
    "대부분 나쁘지않은 결과(80점 이상)으로 나왔지만 그중 점수가 가장 높은 랜덤 포레스트와 Logistic Regression이 가정 적합해 보인다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
